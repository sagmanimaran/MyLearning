{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.learndatasci.com/tutorials/python-pandas-tutorial-complete-introduction-for-beginners/\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series and Dataframes\n",
    "\n",
    "# Series is basically a column\n",
    "# Dataframe is a multidimensional table made up of a collection of series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Series\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "dtype: int64\n",
      "My Series with a name and different Index\n",
      "One      1\n",
      "Two      2\n",
      "Three    3\n",
      "Four     4\n",
      "Name: Numbers, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating a Series\n",
    "# Syntax : pandas.Series(data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)\n",
    "\n",
    "mySeries=pd.Series([1,2,3,4])\n",
    "print(\"My Series\")\n",
    "print(mySeries)\n",
    "\n",
    "#Creating Series with a name and different Index\n",
    "mySeries=pd.Series([1,2,3,4],name=\"Numbers\",index=[\"One\",\"Two\",\"Three\",\"Four\"])\n",
    "print(\"My Series with a name and different Index\")\n",
    "print(mySeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Apples  Orange\n",
      "0       1       1\n",
      "1       2       2\n",
      "2       3       3\n",
      "3       4       4\n",
      "           Apples  Orange\n",
      "June            1       1\n",
      "July            2       2\n",
      "August          3       3\n",
      "September       4       4\n",
      "           Apples  Orange\n",
      "June          1.0     1.0\n",
      "July          2.0     2.0\n",
      "August        3.0     3.0\n",
      "September     4.0     4.0\n",
      "Locating Data with index: June\n",
      "Apples    1\n",
      "Orange    1\n",
      "Name: June, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataframe\n",
    "# Syntax : pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)\n",
    "\n",
    "myDataFrame=pd.DataFrame({ \"Apples\":[1,2,3,4], \"Orange\":[1,2,3,4]})\n",
    "print(myDataFrame)\n",
    "\n",
    "# Creating the dataframe with a index\n",
    "myDataFrame=pd.DataFrame({\"Apples\":[1,2,3,4],\"Orange\":[1,2,3,4]},index=[\"June\",\"July\",\"August\",\"September\"])\n",
    "print(myDataFrame)\n",
    "\n",
    "#Creating the dataframe with a particular datatype\n",
    "myDataFrame1=pd.DataFrame({\"Apples\":[1,2,3,4],\"Orange\":[1,2,3,4]},index=[\"June\",\"July\",\"August\",\"September\"],dtype=np.float64)\n",
    "print(myDataFrame1)\n",
    "\n",
    "\n",
    "# Locating a particular index\n",
    "print(\"Locating Data with index: June\")\n",
    "print(myDataFrame.loc[\"June\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Code  2010  2011  2012  2013\n",
      "0     1   100   101   102   103\n",
      "1     2   102   103   104   105\n",
      "2     3   500   501   502   503\n",
      "3     4  1400  1401  1402  1403\n",
      "4     5   123   124   125   126\n",
      "      2010  2011  2012  2013\n",
      "Code                        \n",
      "1      100   101   102   103\n",
      "2      102   103   104   105\n",
      "3      500   501   502   503\n",
      "4     1400  1401  1402  1403\n",
      "5      123   124   125   126\n",
      "      Code  2011  2012  2013\n",
      "2010                        \n",
      "100      1   101   102   103\n",
      "102      2   103   104   105\n",
      "500      3   501   502   503\n",
      "1400     4  1401  1402  1403\n",
      "123      5   124   125   126\n"
     ]
    }
   ],
   "source": [
    "# Reading file\n",
    "\n",
    "myDataFramefromFile=pd.read_csv('D:/Demo.csv')\n",
    "print(myDataFramefromFile)\n",
    "\n",
    "# for csv files there is no index, so we need to initialize the index\n",
    "#index_col=0 denotes the first column\n",
    "\n",
    "myDataFramefromFile=pd.read_csv('D:/Demo.csv',index_col=0)\n",
    "print(myDataFramefromFile)\n",
    "\n",
    "#index_col=1 denotes the second column\n",
    "\n",
    "myDataFramefromFile=pd.read_csv('D:/Demo.csv',index_col=1)\n",
    "print(myDataFramefromFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Code  2010  2011  2012  2013\n",
      "0     1   100   101   102   103\n",
      "1     2   102   103   104   105\n",
      "2     3   500   501   502   503\n",
      "3     4  1400  1401  1402  1403\n",
      "4     5   123   124   125   126\n"
     ]
    }
   ],
   "source": [
    "# Converting File Formats\n",
    "\n",
    "myDataFramefromFile=pd.read_csv('D:/Demo.csv')\n",
    "convertedFile=myDataFramefromFile.to_json('D:/Demo.json')\n",
    "myDataFramefromJSON=pd.read_json('D:/Demo.json')\n",
    "print(myDataFramefromJSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Top 5 Rows\n",
      "   Row ID        Order ID Order Date  Ship Date       Ship Mode  \\\n",
      "0  5328.0  CA-2011-130813 2013-01-06 2013-01-08    Second Class   \n",
      "1  4938.0  CA-2011-157147 2013-01-13 2013-01-18  Standard Class   \n",
      "2  4939.0  CA-2011-157147 2013-01-13 2013-01-18  Standard Class   \n",
      "3  4940.0  CA-2011-157147 2013-01-13 2013-01-18  Standard Class   \n",
      "4  5365.0  CA-2011-123477 2013-01-18 2013-01-21    Second Class   \n",
      "\n",
      "        Product ID                                   Product Name  \n",
      "0  OFF-PA-10002005                                      Xerox 225  \n",
      "1  OFF-ST-10000078          Tennsco 6- and 18-Compartment Lockers  \n",
      "2  FUR-BO-10003034  O'Sullivan Elevations Bookcase, Cherry Finish  \n",
      "3  OFF-AR-10003514                   4009 Highlighters by Sanford  \n",
      "4  OFF-AP-10000692      Fellowes Mighty 8 Compact Surge Protector  \n",
      "Printing Bottom 3 Rows\n",
      "       Row ID        Order ID Order Date Ship Date       Ship Mode  \\\n",
      "3215  54414.0  CA-2014-693529        NaT       NaT  Standard Class   \n",
      "3216  58208.0  CA-2014-734822        NaT       NaT  Standard Class   \n",
      "3217      NaN  CA-2014-776115        NaT       NaT  Standard Class   \n",
      "\n",
      "           Product ID Product Name  \n",
      "3215              NaN          NaN  \n",
      "3216  OFF-BI-10002101          NaN  \n",
      "3217  OFF-BI-10004630          NaN  \n",
      "Printing info about the file\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3218 entries, 0 to 3217\n",
      "Data columns (total 7 columns):\n",
      "Row ID          3217 non-null float64\n",
      "Order ID        3218 non-null object\n",
      "Order Date      3215 non-null datetime64[ns]\n",
      "Ship Date       3215 non-null datetime64[ns]\n",
      "Ship Mode       3218 non-null object\n",
      "Product ID      3213 non-null object\n",
      "Product Name    3203 non-null object\n",
      "dtypes: datetime64[ns](2), float64(1), object(4)\n",
      "memory usage: 176.1+ KB\n",
      "None\n",
      "Shape of the file (rows,columns)\n",
      "(3218, 7)\n"
     ]
    }
   ],
   "source": [
    "#Few Operations\n",
    "\n",
    "myData=pd.read_excel(r'D:/Furniture Sales.xlsx')\n",
    "\n",
    "#Selecting top 5 rows\n",
    "print(\"Printing Top 5 Rows\")\n",
    "print(myData.head())\n",
    "\n",
    "#Selecting bottom 3 rows\n",
    "print(\"Printing Bottom 3 Rows\")\n",
    "print(myData.tail(3))\n",
    "\n",
    "#Information about the file\n",
    "print(\"Printing info about the file\")\n",
    "print(myData.info())\n",
    "\n",
    "#Shape of the file\n",
    "print(\"Shape of the file (rows,columns)\")\n",
    "print(myData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of MyData :  (3218, 7)\n",
      "Shape of Temp (6436, 7)\n",
      "Shape of Temp after eliminating duplicates (3218, 7)\n",
      "(6436, 7)\n",
      "(3218, 7)\n",
      "(6436, 7)\n",
      "(9654, 7)\n",
      "(3218, 7)\n"
     ]
    }
   ],
   "source": [
    "# Duplicating dataframe\n",
    "\n",
    "temp=myData.append(myData)\n",
    "print(\"Shape of MyData : \",myData.shape)\n",
    "print(\"Shape of Temp\",temp.shape)\n",
    "\n",
    "# Eliminating the duplicates\n",
    "temp=temp.drop_duplicates()\n",
    "print(\"Shape of Temp after eliminating duplicates\",temp.shape)\n",
    "\n",
    "# inplace\n",
    "# in the above example we are doing and assigning to the temp. So without assigning, we can inplace them directly\n",
    "\n",
    "temp=myData.append(myData)\n",
    "print(temp.shape)\n",
    "temp.drop_duplicates(inplace=True)\n",
    "print(temp.shape)\n",
    "\n",
    "# keep\n",
    "# 'first' - drop duplicates after first occurance\n",
    "# 'last' - drop duplicates except for the last occurace\n",
    "# False - drop all duplicates\n",
    "temp=myData.append(myData)\n",
    "print(temp.shape)\n",
    "temp=temp.append(myData)\n",
    "print(temp.shape)\n",
    "temp.drop_duplicates(inplace=True, keep='last')\n",
    "print(temp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Row ID', 'Order ID', 'Order Date', 'Ship Date', 'Ship Mode',\n",
      "       'Product ID', 'Product Name'],\n",
      "      dtype='object')\n",
      "Index(['Row_ID', 'Order_ID', 'Order Date', 'Ship_Date', 'Ship Mode',\n",
      "       'Product ID', 'Product Name'],\n",
      "      dtype='object')\n",
      "Index(['ROW ID', 'ORDER ID', 'ORDER DATE', 'SHIP DATE', 'SHIP MODE',\n",
      "       'PRODUCT ID', 'PRODUCT NAME'],\n",
      "      dtype='object')\n",
      "Index(['row id', 'order id', 'order date', 'ship date', 'ship mode',\n",
      "       'product id', 'product name'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Cleaning Columns\n",
    "\n",
    "# printing the column names \n",
    "print(myData.columns)\n",
    "\n",
    "#renaming the column names\n",
    "myData.rename(columns={\"Row ID\":\"Row_ID\", \"Order ID\":\"Order_ID\",\"Ship Date\":\"Ship_Date\"},inplace=True)\n",
    "print(myData.columns)\n",
    "\n",
    "#without renaming we can convert the column names directly but all the column titles should present\n",
    "myData.columns=['ROW ID','ORDER ID','ORDER DATE','SHIP DATE','SHIP MODE','PRODUCT ID','PRODUCT NAME']\n",
    "print(myData.columns)\n",
    "\n",
    "#even simpler is we can use list or dictionary comprehensions to convert the column titles incase of changing the Cases\n",
    "\n",
    "myData.columns=[column.lower() for column in myData]\n",
    "print(myData.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row id           1\n",
      "order id         0\n",
      "order date       3\n",
      "ship date        3\n",
      "ship mode        0\n",
      "product id       5\n",
      "product name    15\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Missing values\n",
    "# Two ways of dealing with nulls : 1. Drop Null Rows or Columns 2. Replacing null with some not null values(IMPUTATION)\n",
    "\n",
    "# finding the columns having null values\n",
    "myData.isnull()\n",
    "\n",
    "#counting number of nulls in each column\n",
    "print(myData.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows and Column before dropping null values :  (3218, 7)\n",
      "(3203, 7)\n"
     ]
    }
   ],
   "source": [
    "#removing null values\n",
    "print(\"Rows and Column before dropping null values : \",myData.shape)\n",
    "#print(\"Rows and Column after dropping null values : \",myData.dropna().shape)\n",
    "#myData.dropna() will return a dataframe which is created from the original dataframe without null values \n",
    "\n",
    "#removing null values particularly in rows and columns\n",
    "#axis 0 for rows and axis 1 for columns\n",
    "print(myData.dropna(axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5004.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "row id           0\n",
       "order id         0\n",
       "order date       3\n",
       "ship date        3\n",
       "ship mode        0\n",
       "product id       5\n",
       "product name    15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imputation\n",
    "\n",
    "#copying row id column to a variable\n",
    "rowid=myData['row id']\n",
    "\n",
    "#finding median values from the values in the row id\n",
    "median=rowid.median()\n",
    "print(median)\n",
    "\n",
    "#filling null values with the median value in the myData\n",
    "rowid.fillna(median,inplace=True)\n",
    "\n",
    "#checking the null in the row id in myData\n",
    "myData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Staples                                                                  13\n",
       "Staple envelope                                                          10\n",
       "Easy-staple paper                                                         9\n",
       "Avery Non-Stick Binders                                                   8\n",
       "Cardinal Slant-D Ring Binder, Heavy Gauge Vinyl                           7\n",
       "Bretford Rectangular Conference Table Tops                                7\n",
       "Xerox 225                                                                 7\n",
       "Staples in misc. colors                                                   7\n",
       "Vinyl Sectional Post Binders                                              7\n",
       "SAFCO Arco Folding Chair                                                  7\n",
       "Global Troy Executive Leather Low-Back Tilter                             7\n",
       "GBC Standard Therm-A-Bind Covers                                          6\n",
       "Global Deluxe Stacking Chair, Gray                                        6\n",
       "Cardinal Holdit Business Card Pockets                                     6\n",
       "Novimex Fabric Task Chair                                                 6\n",
       "O'Sullivan Living Dimensions 2-Shelf Bookcases                            6\n",
       "Staple holder                                                             6\n",
       "Fellowes Super Stor/Drawer Files                                          6\n",
       "GuestStacker Chair with Chrome Finish Legs                                6\n",
       "Sterilite Officeware Hinged File Box                                      6\n",
       "Kingston Digital DataTraveler 16GB USB 2.0                                6\n",
       "Prang Drawing Pencil Set                                                  6\n",
       "Wilson Jones Leather-Like Binders with DublLock Round Rings               6\n",
       "Dana Halogen Swing-Arm Architect Lamp                                     6\n",
       "Carina Double Wide Media Storage Towers in Natural & Black                6\n",
       "SAFCO Boltless Steel Shelving                                             6\n",
       "Wilson Jones Easy Flow II Sheet Lifters                                   5\n",
       "Recycled Pressboard Report Cover with Reinforced Top Hinge                5\n",
       "Eldon Portable Mobile Manager                                             5\n",
       "Fellowes Mobile File Cart, Black                                          5\n",
       "                                                                         ..\n",
       "Cisco SPA508G                                                             1\n",
       "Office Star Flex Back Scooter Chair with White Frame                      1\n",
       "Eldon File Chest Portable File                                            1\n",
       "Wirebound Message Books, 2 7/8\" x 5\", 3 Forms per Page                    1\n",
       "Hypercom P1300 Pinpad                                                     1\n",
       "Acco Smartsocket Table Surge Protector, 6 Color-Coded Adapter Outlets     1\n",
       "Pastel Pink Envelopes                                                     1\n",
       "Maxell 4.7GB DVD+RW 3/Pack                                                1\n",
       "Luxo Professional Fluorescent Magnifier Lamp with Clamp-Mount Base        1\n",
       "Avery Durable Poly Binders                                                1\n",
       "GBC Instant Index System for Binding Systems                              1\n",
       "X-Rack File for Hanging Folders                                           1\n",
       "Tops White Computer Printout Paper                                        1\n",
       "Black Avery Memo-Size 3-Ring Binder, 5 1/2\" x 8 1/2\"                      1\n",
       "Weyerhaeuser First Choice Laser/Copy Paper (20Lb. and 88 Bright)          1\n",
       "Tennsco Single-Tier Lockers                                               1\n",
       "Samsung Galaxy S III - 16GB - pebble blue (T-Mobile)                      1\n",
       "Xerox 1922                                                                1\n",
       "Samsung Galaxy Note 3                                                     1\n",
       "Imation 32GB Pocket Pro USB 3.0 Flash Drive - 32 GB - Black - 1 P ...     1\n",
       "Logitech Keyboard K120                                                    1\n",
       "Hammermill CopyPlus Copy Paper (20Lb. and 84 Bright)                      1\n",
       "Wilson Jones Century Plastic Molded Ring Binders                          1\n",
       "Eureka Sanitaire  Multi-Pro Heavy-Duty Upright, Disposable Bags           1\n",
       "Wilson SignalBoost 841262 DB PRO Amplifier Kit                            1\n",
       "Eldon \"L\" Workstation Diamond Chairmat                                    1\n",
       "Polycom VVX 310 VoIP phone                                                1\n",
       "Xerox 232                                                                 1\n",
       "HP Office Recycled Paper (20Lb. and 87 Bright)                            1\n",
       "QVS USB Car Charger 2-Port 2.1Amp for iPod/iPhone/iPad/iPad 2/iPad 3      1\n",
       "Name: product name, Length: 1503, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myData.describe()\n",
    "#describe shows only row id because it is the only column in integer format\n",
    "\n",
    "#for the other columns\n",
    "myData['product name'].describe()\n",
    "\n",
    "#to show how frequent all the products\n",
    "myData['product name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>row id</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        row id\n",
       "row id     1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation\n",
    "myData.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row id', 'order id', 'order date', 'ship date', 'ship mode',\n",
      "       'product id', 'product name'],\n",
      "      dtype='object')\n",
      "         order id order date\n",
      "0  CA-2011-130813 2013-01-06\n",
      "1  CA-2011-157147 2013-01-13\n",
      "2  CA-2011-157147 2013-01-13\n",
      "3  CA-2011-157147 2013-01-13\n",
      "4  CA-2011-123477 2013-01-18\n",
      "5  CA-2011-146591 2013-01-19\n",
      "6  CA-2011-146591 2013-01-19\n",
      "7  CA-2011-146591 2013-01-19\n",
      "8  CA-2011-146591 2013-01-19\n",
      "9  CA-2011-148614 2013-01-20\n"
     ]
    }
   ],
   "source": [
    "# More into Data Slicing\n",
    "# Series extraction and Dataframe Extraction\n",
    "\n",
    "row=myData['row id']\n",
    "type(row)\n",
    "\n",
    "print(myData.columns)\n",
    "\n",
    "orderidanddate=myData[['order id','order date']]\n",
    "type(orderidanddate)\n",
    "\n",
    "print(orderidanddate.head(10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row id                                           4938\n",
      "order id                               CA-2011-157147\n",
      "order date                        2013-01-13 00:00:00\n",
      "ship date                         2013-01-18 00:00:00\n",
      "ship mode                              Standard Class\n",
      "product id                            OFF-ST-10000078\n",
      "product name    Tennsco 6- and 18-Compartment Lockers\n",
      "Name: 1, dtype: object\n",
      "row id                                           4938\n",
      "order id                               CA-2011-157147\n",
      "order date                        2013-01-13 00:00:00\n",
      "ship date                         2013-01-18 00:00:00\n",
      "ship mode                              Standard Class\n",
      "product id                            OFF-ST-10000078\n",
      "product name    Tennsco 6- and 18-Compartment Lockers\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Row Extraction\n",
    "#loc and iloc\n",
    "#loc[] - identifying location through name of the index\n",
    "#iloc[] - identifying location through the numerical index\n",
    "\n",
    "print(myData.loc[1])\n",
    "# 1 denotes the name of the index, if the index is in the form of text then it corresponds to the name\n",
    "\n",
    "print(myData.iloc[1])\n",
    "# 1 denotes the numerical position of the number 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "5        True\n",
      "6        True\n",
      "7        True\n",
      "8        True\n",
      "9       False\n",
      "10      False\n",
      "11      False\n",
      "12      False\n",
      "13      False\n",
      "14      False\n",
      "15       True\n",
      "16      False\n",
      "17      False\n",
      "18      False\n",
      "19      False\n",
      "20      False\n",
      "21      False\n",
      "22       True\n",
      "23      False\n",
      "24      False\n",
      "25      False\n",
      "26      False\n",
      "27      False\n",
      "28      False\n",
      "29       True\n",
      "        ...  \n",
      "3188    False\n",
      "3189    False\n",
      "3190    False\n",
      "3191    False\n",
      "3192     True\n",
      "3193    False\n",
      "3194    False\n",
      "3195    False\n",
      "3196    False\n",
      "3197    False\n",
      "3198    False\n",
      "3199    False\n",
      "3200    False\n",
      "3201    False\n",
      "3202    False\n",
      "3203    False\n",
      "3204    False\n",
      "3205    False\n",
      "3206    False\n",
      "3207    False\n",
      "3208    False\n",
      "3209    False\n",
      "3210    False\n",
      "3211    False\n",
      "3212    False\n",
      "3213    False\n",
      "3214    False\n",
      "3215    False\n",
      "3216    False\n",
      "3217    False\n",
      "Name: ship mode, Length: 3218, dtype: bool\n",
      "      row id        order id order date  ship date    ship mode  \\\n",
      "5     5463.0  CA-2011-146591 2013-01-19 2013-01-20  First Class   \n",
      "6     5464.0  CA-2011-146591 2013-01-19 2013-01-20  First Class   \n",
      "7     5465.0  CA-2011-146591 2013-01-19 2013-01-20  First Class   \n",
      "8     5466.0  CA-2011-146591 2013-01-19 2013-01-20  First Class   \n",
      "15    3366.0  CA-2011-115161 2013-01-31 2013-02-02  First Class   \n",
      "22    9267.0  CA-2011-125759 2013-02-08 2013-02-09  First Class   \n",
      "29    7611.0  CA-2011-133354 2013-02-22 2013-02-24  First Class   \n",
      "34    4962.0  CA-2011-156587 2013-03-07 2013-03-08  First Class   \n",
      "35    4963.0  CA-2011-156587 2013-03-07 2013-03-08  First Class   \n",
      "36    4964.0  CA-2011-156587 2013-03-07 2013-03-08  First Class   \n",
      "82    4845.0  US-2011-128685 2013-04-04 2013-04-05  First Class   \n",
      "123   8452.0  CA-2011-131387 2013-04-28 2013-04-30  First Class   \n",
      "124   7999.0  US-2011-148194 2013-05-04 2013-05-07  First Class   \n",
      "125   8000.0  US-2011-148194 2013-05-04 2013-05-07  First Class   \n",
      "149   2761.0  CA-2011-129574 2013-05-26 2013-05-29  First Class   \n",
      "180    422.0  CA-2011-142048 2013-06-22 2013-06-25  First Class   \n",
      "183   1098.0  CA-2011-159338 2013-06-25 2013-06-28  First Class   \n",
      "189   6733.0  CA-2011-120096 2013-07-04 2013-07-07  First Class   \n",
      "190   6734.0  CA-2011-120096 2013-07-04 2013-07-07  First Class   \n",
      "212   5969.0  CA-2011-141726 2013-07-20 2013-07-22  First Class   \n",
      "213   5970.0  CA-2011-141726 2013-07-20 2013-07-22  First Class   \n",
      "214   5971.0  CA-2011-141726 2013-07-20 2013-07-22  First Class   \n",
      "215   5972.0  CA-2011-141726 2013-07-20 2013-07-22  First Class   \n",
      "216   7229.0  CA-2011-157546 2013-07-20 2013-07-22  First Class   \n",
      "217   7230.0  CA-2011-157546 2013-07-20 2013-07-22  First Class   \n",
      "218   8130.0  CA-2011-127866 2013-07-20 2013-07-23  First Class   \n",
      "219   8131.0  CA-2011-127866 2013-07-20 2013-07-23  First Class   \n",
      "220   8132.0  CA-2011-127866 2013-07-20 2013-07-23  First Class   \n",
      "221   8133.0  CA-2011-127866 2013-07-20 2013-07-23  First Class   \n",
      "251   2173.0  CA-2011-152296 2013-08-01 2013-08-03  First Class   \n",
      "...      ...             ...        ...        ...          ...   \n",
      "3002  1653.0  US-2014-132444 2016-11-18 2016-11-21  First Class   \n",
      "3003  1654.0  US-2014-132444 2016-11-18 2016-11-21  First Class   \n",
      "3004  1655.0  US-2014-132444 2016-11-18 2016-11-21  First Class   \n",
      "3005  1656.0  US-2014-132444 2016-11-18 2016-11-21  First Class   \n",
      "3006  1657.0  US-2014-132444 2016-11-18 2016-11-21  First Class   \n",
      "3007  1479.0  CA-2014-121468 2016-11-19 2016-11-20  First Class   \n",
      "3026  4765.0  CA-2014-123701 2016-11-24 2016-11-27  First Class   \n",
      "3041  1928.0  CA-2014-121538 2016-11-28 2016-12-01  First Class   \n",
      "3043  6300.0  CA-2014-107314 2016-11-30 2016-12-03  First Class   \n",
      "3057  1753.0  CA-2014-116715 2016-12-02 2016-12-05  First Class   \n",
      "3058  1754.0  CA-2014-116715 2016-12-02 2016-12-05  First Class   \n",
      "3059  1755.0  CA-2014-116715 2016-12-02 2016-12-05  First Class   \n",
      "3086  8391.0  CA-2014-153227 2016-12-04 2016-12-06  First Class   \n",
      "3090  9525.0  CA-2014-156958 2016-12-05 2016-12-06  First Class   \n",
      "3091  9526.0  CA-2014-156958 2016-12-05 2016-12-06  First Class   \n",
      "3092  9527.0  CA-2014-156958 2016-12-05 2016-12-06  First Class   \n",
      "3093  9528.0  CA-2014-156958 2016-12-05 2016-12-06  First Class   \n",
      "3094  9529.0  CA-2014-156958 2016-12-05 2016-12-06  First Class   \n",
      "3096   566.0  CA-2014-137099 2016-12-07 2016-12-10  First Class   \n",
      "3107  3431.0  CA-2014-148264 2016-12-08 2016-12-09  First Class   \n",
      "3108  3432.0  CA-2014-148264 2016-12-08 2016-12-09  First Class   \n",
      "3109  3433.0  CA-2014-148264 2016-12-08 2016-12-09  First Class   \n",
      "3155  1025.0  CA-2014-106964 2016-12-17 2016-12-20  First Class   \n",
      "3161  2887.0  CA-2014-102099 2016-12-18 2016-12-19  First Class   \n",
      "3162  2888.0  CA-2014-102099 2016-12-18 2016-12-19  First Class   \n",
      "3163  2889.0  CA-2014-102099 2016-12-18 2016-12-19  First Class   \n",
      "3178  8178.0  CA-2014-149699 2016-12-22 2016-12-24  First Class   \n",
      "3181  4620.0  CA-2014-145219 2016-12-24 2016-12-25  First Class   \n",
      "3182  4621.0  CA-2014-145219 2016-12-24 2016-12-25  First Class   \n",
      "3192  6150.0  CA-2014-101322 2016-12-28 2016-12-31  First Class   \n",
      "\n",
      "           product id                                       product name  \n",
      "5     OFF-BI-10003676  GBC Standard Recycled Report Covers, Clear Pla...  \n",
      "6     OFF-PA-10000659  TOPS Carbonless Receipt Book, Four 2-3/4 x 7-1...  \n",
      "7     OFF-EN-10002504  Tyvek  Top-Opening Peel & Seel Envelopes, Plai...  \n",
      "8     FUR-BO-10001972         O'Sullivan 4-Shelf Bookcase in Odessa Pine  \n",
      "15    FUR-BO-10003966  Sauder Facets Collection Library, Sky Alder Fi...  \n",
      "22    FUR-FU-10002111               Master Caster Door Stop, Large Brown  \n",
      "29    OFF-PA-10001800                                          Xerox 220  \n",
      "34    FUR-CH-10004477         Global Push Button Manager's Chair, Indigo  \n",
      "35    OFF-AR-10001427                                         Newell 330  \n",
      "36    OFF-ST-10002344            Carina 42\"Hx23 3/4\"W Media Storage Unit  \n",
      "82    OFF-BI-10004140                            Avery Non-Stick Binders  \n",
      "123   TEC-PH-10001459                            Samsung Galaxy Mega 6.3  \n",
      "124   FUR-FU-10001852  Eldon Regeneration Recycled Desk Accessories, ...  \n",
      "125   OFF-AP-10000696                                Holmes Odor Grabber  \n",
      "149   OFF-PA-10002893          Wirebound Service Call Books, 5 1/2\" x 4\"  \n",
      "180   TEC-AC-10004114           KeyTronic 6101 Series - Keyboard - Black  \n",
      "183   FUR-TA-10004147                             Hon 4060 Series Tables  \n",
      "189   OFF-PA-10001977                                          Xerox 194  \n",
      "190   OFF-AP-10000692          Fellowes Mighty 8 Compact Surge Protector  \n",
      "212   OFF-PA-10000418                                          Xerox 189  \n",
      "213   OFF-BI-10001982         Wilson Jones Custom Binder Spines & Labels  \n",
      "214   OFF-PA-10002230                                         Xerox 1897  \n",
      "215   FUR-FU-10003577                         Nu-Dell Leatherette Frames  \n",
      "216   OFF-BI-10002498                     Clear Mylar Reinforcing Strips  \n",
      "217   OFF-PA-10004569  Wirebound Message Books, Two 4 1/4\" x 5\" Forms...  \n",
      "218   TEC-AC-10000023             Maxell 74 Minute CD-R Spindle, 50/Pack  \n",
      "219   OFF-PA-10003971                                         Xerox 1965  \n",
      "220   OFF-AR-10003481                                         Newell 348  \n",
      "221   OFF-ST-10001490                     Hot File 7-Pocket, Floor Stand  \n",
      "251   OFF-BI-10004506  Wilson Jones data.warehouse D-Ring Binders wit...  \n",
      "...               ...                                                ...  \n",
      "3002  OFF-ST-10003442                      Eldon Portable Mobile Manager  \n",
      "3003  TEC-AC-10003832  Imation 16GB Mini TravelDrive USB 2.0 Flash Drive  \n",
      "3004  OFF-FA-10000611                                Binder Clips by OIC  \n",
      "3005  OFF-BI-10001116      Wilson Jones 1\" Hanging DublLock Ring Binders  \n",
      "3006  OFF-ST-10000563        Fellowes Bankers Box Stor/Drawer Steel Plus  \n",
      "3007  TEC-PH-10000376                          Square Credit Card Reader  \n",
      "3026  OFF-AR-10001860                              BIC Liqua Brite Liner  \n",
      "3041  OFF-PA-10004071  Eaton Premium Continuous-Feed Paper, 25% Cotto...  \n",
      "3043  FUR-FU-10003489                      Contemporary Borderless Frame  \n",
      "3057  OFF-ST-10004340                   Fellowes Mobile File Cart, Black  \n",
      "3058  OFF-PA-10004475                                         Xerox 1940  \n",
      "3059  OFF-PA-10003893                                         Xerox 1962  \n",
      "3086  OFF-PA-10001838  Adams Telephone Message Book W/Dividers/Space ...  \n",
      "3090  OFF-BI-10001524  GBC Premium Transparent Covers with Diagonal L...  \n",
      "3091  FUR-FU-10003268  Eldon Radial Chair Mat for Low to Medium Pile ...  \n",
      "3092  TEC-PH-10000148  Cyber Acoustics AC-202b Speech Recognition Ste...  \n",
      "3093  OFF-BI-10001543               GBC VeloBinder Manual Binding System  \n",
      "3094  OFF-BI-10002071               Fellowes Black Plastic Comb Bindings  \n",
      "3096  TEC-PH-10002496                                       Cisco SPA301  \n",
      "3107  OFF-ST-10003327                           Akro-Mils 12-Gallon Tote  \n",
      "3108  FUR-FU-10002703  Tenex Traditional Chairmats for Hard Floors, A...  \n",
      "3109  OFF-PA-10003651                                         Xerox 1968  \n",
      "3155  OFF-BI-10000320                          GBC Plastic Binding Combs  \n",
      "3161  OFF-AR-10003811                                         Newell 327  \n",
      "3162  OFF-PA-10003172                                         Xerox 1996  \n",
      "3163  OFF-PA-10000289                                          Xerox 213  \n",
      "3178  TEC-AC-10000474  Kensington Expert Mouse Optical USB Trackball ...  \n",
      "3181  TEC-CO-10001449               Hewlett Packard LaserJet 3310 Copier  \n",
      "3182  OFF-BI-10001670                       Vinyl Sectional Post Binders  \n",
      "3192  FUR-CH-10003968                           Novimex Turbo Task Chair  \n",
      "\n",
      "[515 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#Conditional Extraction\n",
    "\n",
    "condition=(myData['ship mode']=='First Class')\n",
    "print(condition)\n",
    "#it returns all the values including true and false\n",
    "\n",
    "#to get only the true values we need to pass it as a dataframe\n",
    "\n",
    "condition=myData[myData['ship mode']=='First Class']\n",
    "print(condition)\n",
    "\n",
    "#Make sure to find the difference between the two\n",
    "# condition=      (myData['ship mode']=='First Class')\n",
    "# condition=myData[myData['ship mode']=='First Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row id          1136\n",
      "order id        1136\n",
      "order date      1136\n",
      "ship date       1136\n",
      "ship mode       1136\n",
      "product id      1136\n",
      "product name    1136\n",
      "dtype: int64\n",
      "row id          1136\n",
      "order id        1136\n",
      "order date      1136\n",
      "ship date       1136\n",
      "ship mode       1136\n",
      "product id      1136\n",
      "product name    1136\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Few more Try\n",
    "\n",
    "condition=myData[(myData['ship mode']=='First Class') | (myData['ship mode']== 'Second Class')]\n",
    "print(condition.count())\n",
    "\n",
    "#another way to do the above operation\n",
    "#isin\n",
    "condition=myData[myData['ship mode'].isin(['First Class','Second Class'])]\n",
    "print(condition.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       row id        order id order date  ship date       ship mode  \\\n",
      "0      5328.0  CA-2011-130813 2013-01-06 2013-01-08    Second Class   \n",
      "1      4938.0  CA-2011-157147 2013-01-13 2013-01-18  Standard Class   \n",
      "2      4939.0  CA-2011-157147 2013-01-13 2013-01-18  Standard Class   \n",
      "3      4940.0  CA-2011-157147 2013-01-13 2013-01-18  Standard Class   \n",
      "4      5365.0  CA-2011-123477 2013-01-18 2013-01-21    Second Class   \n",
      "5      5463.0  CA-2011-146591 2013-01-19 2013-01-20     First Class   \n",
      "6      5464.0  CA-2011-146591 2013-01-19 2013-01-20     First Class   \n",
      "7      5465.0  CA-2011-146591 2013-01-19 2013-01-20     First Class   \n",
      "8      5466.0  CA-2011-146591 2013-01-19 2013-01-20     First Class   \n",
      "9      5737.0  CA-2011-148614 2013-01-20 2013-01-25  Standard Class   \n",
      "10     5738.0  CA-2011-148614 2013-01-20 2013-01-25  Standard Class   \n",
      "11     9156.0  CA-2011-102645 2013-01-23 2013-01-28  Standard Class   \n",
      "12     3795.0  US-2011-117163 2013-01-27 2013-02-02  Standard Class   \n",
      "13     3796.0  US-2011-117163 2013-01-27 2013-02-02  Standard Class   \n",
      "14     3797.0  US-2011-117163 2013-01-27 2013-02-02  Standard Class   \n",
      "15     3366.0  CA-2011-115161 2013-01-31 2013-02-02     First Class   \n",
      "16     1704.0  CA-2011-139857 2013-02-02 2013-02-06  Standard Class   \n",
      "17     1518.0  CA-2011-111059 2013-02-03 2013-02-06    Second Class   \n",
      "18     1519.0  CA-2011-111059 2013-02-03 2013-02-06    Second Class   \n",
      "19     1544.0  CA-2011-107181 2013-02-04 2013-02-08  Standard Class   \n",
      "20     1545.0  CA-2011-107181 2013-02-04 2013-02-08  Standard Class   \n",
      "21     8585.0  CA-2011-104808 2013-02-04 2013-02-08    Second Class   \n",
      "22     9267.0  CA-2011-125759 2013-02-08 2013-02-09     First Class   \n",
      "23      457.0  US-2011-110674 2013-02-12 2013-02-18  Standard Class   \n",
      "24     9762.0  CA-2011-121762 2013-02-14 2013-02-18  Standard Class   \n",
      "25     9763.0  CA-2011-121762 2013-02-14 2013-02-18  Standard Class   \n",
      "26     9764.0  CA-2011-121762 2013-02-14 2013-02-18  Standard Class   \n",
      "27     7438.0  CA-2011-165568 2013-02-15 2013-02-19  Standard Class   \n",
      "28     8504.0  CA-2011-164903 2013-02-20 2013-02-24  Standard Class   \n",
      "29     7611.0  CA-2011-133354 2013-02-22 2013-02-24     First Class   \n",
      "...       ...             ...        ...        ...             ...   \n",
      "3188   6807.0  CA-2014-162880 2016-12-25 2016-12-29  Standard Class   \n",
      "3189    271.0  CA-2014-163979 2016-12-28 2017-01-02    Second Class   \n",
      "3190   2432.0  CA-2014-129805 2016-12-28 2017-01-02  Standard Class   \n",
      "3191   6090.0  US-2014-162068 2016-12-28 2016-12-31    Second Class   \n",
      "3192   6150.0  CA-2014-101322 2016-12-28 2016-12-31     First Class   \n",
      "3193   8098.0  CA-2014-122798 2016-12-28 2017-01-01  Standard Class   \n",
      "3194   8099.0  CA-2014-122798 2016-12-28 2017-01-01  Standard Class   \n",
      "3195   1878.0  CA-2014-118885 2016-12-29 2017-01-02  Standard Class   \n",
      "3196   1879.0  CA-2014-118885 2016-12-29 2017-01-02  Standard Class   \n",
      "3197   5132.0  CA-2014-146626 2016-12-29 2017-01-05  Standard Class   \n",
      "3198   5457.0  CA-2014-130631 2016-12-29 2017-01-02  Standard Class   \n",
      "3199   5458.0  CA-2014-130631 2016-12-29 2017-01-02  Standard Class   \n",
      "3200   1297.0  CA-2014-115427 2016-12-30 2017-01-03  Standard Class   \n",
      "3201   1298.0  CA-2014-115427 2016-12-30 2017-01-03  Standard Class   \n",
      "3202   5092.0  CA-2014-156720 2016-12-30 2017-01-03  Standard Class   \n",
      "3203   8886.0  CA-2014-198013 2016-12-31 2017-01-03  Standard Class   \n",
      "3204  12680.0  CA-2014-239306 2016-12-31 2017-01-04  Standard Class   \n",
      "3205  16474.0  CA-2014-280599 2017-01-01 2017-01-04  Standard Class   \n",
      "3206  20268.0  CA-2014-321892 2017-01-01 2017-01-04  Standard Class   \n",
      "3207  24062.0  CA-2014-363185 2017-01-02 2017-01-04  Standard Class   \n",
      "3208  27856.0  CA-2014-404478 2017-01-02 2017-01-05  Standard Class   \n",
      "3209  31650.0  CA-2014-445771 2017-01-03 2017-01-05  Standard Class   \n",
      "3210  35444.0  CA-2014-487064 2017-01-03 2017-01-05  Standard Class   \n",
      "3211  39238.0  CA-2014-528357 2017-01-04 2017-01-05  Standard Class   \n",
      "3212  43032.0  CA-2014-569650 2017-01-04 2017-01-06  Standard Class   \n",
      "3213  46826.0  CA-2014-610943 2017-01-05 2017-01-06  Standard Class   \n",
      "3214  50620.0  CA-2014-652236 2017-01-05 2017-01-06  Standard Class   \n",
      "3215  54414.0  CA-2014-693529        NaT        NaT  Standard Class   \n",
      "3216  58208.0  CA-2014-734822        NaT        NaT  Standard Class   \n",
      "3217   5004.0  CA-2014-776115        NaT        NaT  Standard Class   \n",
      "\n",
      "           product id                                       product name  \\\n",
      "0     OFF-PA-10002005                                          Xerox 225   \n",
      "1     OFF-ST-10000078              Tennsco 6- and 18-Compartment Lockers   \n",
      "2     FUR-BO-10003034      O'Sullivan Elevations Bookcase, Cherry Finish   \n",
      "3     OFF-AR-10003514                       4009 Highlighters by Sanford   \n",
      "4     OFF-AP-10000692          Fellowes Mighty 8 Compact Surge Protector   \n",
      "5     OFF-BI-10003676  GBC Standard Recycled Report Covers, Clear Pla...   \n",
      "6     OFF-PA-10000659  TOPS Carbonless Receipt Book, Four 2-3/4 x 7-1...   \n",
      "7     OFF-EN-10002504  Tyvek  Top-Opening Peel & Seel Envelopes, Plai...   \n",
      "8     FUR-BO-10001972         O'Sullivan 4-Shelf Bookcase in Odessa Pine   \n",
      "9     OFF-PA-10002893          Wirebound Service Call Books, 5 1/2\" x 4\"   \n",
      "10    FUR-FU-10003194  Eldon Expressions Desk Accessory, Wood Pencil ...   \n",
      "11    OFF-PA-10001804                                          Xerox 195   \n",
      "12    OFF-ST-10003692  Recycled Steel Personal File for Hanging File ...   \n",
      "13    FUR-TA-10003469           Balt Split Level Computer Training Table   \n",
      "14    OFF-AR-10003179        Dixon Ticonderoga Core-Lock Colored Pencils   \n",
      "15    FUR-BO-10003966  Sauder Facets Collection Library, Sky Alder Fi...   \n",
      "16    OFF-FA-10001843                                            Staples   \n",
      "17    OFF-BI-10004593      Ibico Laser Imprintable Binding System Covers   \n",
      "18    OFF-BI-10002827                         Avery Durable Poly Binders   \n",
      "19    OFF-BI-10004230                 GBC Recycled Grain Textured Covers   \n",
      "20    OFF-PA-10000350  Message Book, Standard Line \"While You Were Ou...   \n",
      "21    OFF-BI-10003676  GBC Standard Recycled Report Covers, Clear Pla...   \n",
      "22    FUR-FU-10002111               Master Caster Door Stop, Large Brown   \n",
      "23    FUR-CH-10000225                 Global Geo Office Task Chair, Gray   \n",
      "24    TEC-AC-10000736                     Logitech G600 MMO Gaming Mouse   \n",
      "25    OFF-AP-10001293                    Belkin 8 Outlet Surge Protector   \n",
      "26    OFF-SU-10000157           Compact Automatic Electric Letter Opener   \n",
      "27    OFF-BI-10001031            Pressboard Data Binders by Wilson Jones   \n",
      "28    OFF-PA-10003363                                          Xerox 204   \n",
      "29    OFF-PA-10001800                                          Xerox 220   \n",
      "...               ...                                                ...   \n",
      "3188  OFF-BI-10003314             Tuff Stuff Recycled Round Ring Binders   \n",
      "3189  OFF-ST-10003208                 Adjustable Depth Letter/Legal Cart   \n",
      "3190  FUR-FU-10001935                   3M Hangers With Command Adhesive   \n",
      "3191  OFF-BI-10002813          Avery Reinforcements for Hole-Punch Pages   \n",
      "3192  FUR-CH-10003968                           Novimex Turbo Task Chair   \n",
      "3193  OFF-ST-10003058  Eldon Mobile Mega Data Cart  Mega Stackable  A...   \n",
      "3194  OFF-PA-10004239                                         Xerox 1953   \n",
      "3195  FUR-CH-10002880          Global High-Back Leather Tilter, Burgundy   \n",
      "3196  TEC-PH-10002563                                   Adtran 1202752G1   \n",
      "3197  FUR-FU-10002501                            Nu-Dell Executive Frame   \n",
      "3198  OFF-FA-10000089                                   Acco Glide Clips   \n",
      "3199  FUR-FU-10004093            Hand-Finished Solid Wood Document Frame   \n",
      "3200  OFF-BI-10002103    Cardinal Slant-D Ring Binder, Heavy Gauge Vinyl   \n",
      "3201  OFF-BI-10004632                                 GBC Binding covers   \n",
      "3202  OFF-FA-10003472                                Bagged Rubber Bands   \n",
      "3203  OFF-FA-10000088                                                NaN   \n",
      "3204  FUR-FU-10004092                                                NaN   \n",
      "3205  OFF-BI-10002102                                                NaN   \n",
      "3206  OFF-BI-10004631                                                NaN   \n",
      "3207  OFF-FA-10003471                                                NaN   \n",
      "3208  OFF-FA-10000087                                                NaN   \n",
      "3209  FUR-FU-10004091                                                NaN   \n",
      "3210              NaN                                                NaN   \n",
      "3211              NaN                                                NaN   \n",
      "3212  OFF-FA-10003470                                                NaN   \n",
      "3213              NaN                                                NaN   \n",
      "3214              NaN                                                NaN   \n",
      "3215              NaN                                                NaN   \n",
      "3216  OFF-BI-10002101                                                NaN   \n",
      "3217  OFF-BI-10004630                                                NaN   \n",
      "\n",
      "     shipmentsuccess  \n",
      "0            Delayed  \n",
      "1      UnSuccessfull  \n",
      "2      UnSuccessfull  \n",
      "3      UnSuccessfull  \n",
      "4            Delayed  \n",
      "5            Success  \n",
      "6            Success  \n",
      "7            Success  \n",
      "8            Success  \n",
      "9      UnSuccessfull  \n",
      "10     UnSuccessfull  \n",
      "11     UnSuccessfull  \n",
      "12     UnSuccessfull  \n",
      "13     UnSuccessfull  \n",
      "14     UnSuccessfull  \n",
      "15           Success  \n",
      "16     UnSuccessfull  \n",
      "17           Delayed  \n",
      "18           Delayed  \n",
      "19     UnSuccessfull  \n",
      "20     UnSuccessfull  \n",
      "21           Delayed  \n",
      "22           Success  \n",
      "23     UnSuccessfull  \n",
      "24     UnSuccessfull  \n",
      "25     UnSuccessfull  \n",
      "26     UnSuccessfull  \n",
      "27     UnSuccessfull  \n",
      "28     UnSuccessfull  \n",
      "29           Success  \n",
      "...              ...  \n",
      "3188   UnSuccessfull  \n",
      "3189         Delayed  \n",
      "3190   UnSuccessfull  \n",
      "3191         Delayed  \n",
      "3192         Success  \n",
      "3193   UnSuccessfull  \n",
      "3194   UnSuccessfull  \n",
      "3195   UnSuccessfull  \n",
      "3196   UnSuccessfull  \n",
      "3197   UnSuccessfull  \n",
      "3198   UnSuccessfull  \n",
      "3199   UnSuccessfull  \n",
      "3200   UnSuccessfull  \n",
      "3201   UnSuccessfull  \n",
      "3202   UnSuccessfull  \n",
      "3203   UnSuccessfull  \n",
      "3204   UnSuccessfull  \n",
      "3205   UnSuccessfull  \n",
      "3206   UnSuccessfull  \n",
      "3207   UnSuccessfull  \n",
      "3208   UnSuccessfull  \n",
      "3209   UnSuccessfull  \n",
      "3210   UnSuccessfull  \n",
      "3211   UnSuccessfull  \n",
      "3212   UnSuccessfull  \n",
      "3213   UnSuccessfull  \n",
      "3214   UnSuccessfull  \n",
      "3215   UnSuccessfull  \n",
      "3216   UnSuccessfull  \n",
      "3217   UnSuccessfull  \n",
      "\n",
      "[3218 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#Applying Functions\n",
    "\n",
    "def shipment_success(x):\n",
    "    if x=='First Class':\n",
    "        return 'Success'\n",
    "    elif x=='Second Class':\n",
    "        return 'Delayed'\n",
    "    else:\n",
    "        return 'UnSuccessfull'\n",
    "    \n",
    "\n",
    "myData[\"shipmentsuccess\"]=myData['ship mode'].apply(shipment_success)\n",
    "print(myData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
